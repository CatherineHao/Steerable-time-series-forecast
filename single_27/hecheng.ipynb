{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 针对predict_data不是一行的问题\n",
    "need_path = './weighted9_skip6_0.8.csv'\n",
    "need_data = pd.read_csv(need_path)\n",
    "for index, row in need_data.iterrows():\n",
    "    pre_data = row['predict_data']\n",
    "    # print(pre_data)\n",
    "    pre_data = pre_data.replace(\"[\",\"\")\n",
    "    pre_data = pre_data.replace(']',\"\")\n",
    "    pre_data = pre_data.replace(\"\\n\",\"\")\n",
    "    pre_data = pre_data.replace(\"\\r\",\"\")\n",
    "    row['predict_data']=pre_data\n",
    "    need_data.iloc[index] = row\n",
    "need_data.head()\n",
    "need_data.to_csv(need_path,header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始合并：\n",
      "合并rawdata_skip13_0.8.csv\n",
      "合并rawdata_skip1_0.8.csv\n",
      "合并rawdata_skip3_0.8.csv\n",
      "合并rawdata_skip6_0.8.csv\n",
      "合并rolling13_skip13_0.8.csv\n",
      "合并rolling13_skip1_0.8.csv\n",
      "合并rolling13_skip3_0.8.csv\n",
      "合并rolling13_skip6_0.8.csv\n",
      "合并rolling3_skip13_0.8.csv\n",
      "合并rolling3_skip1_0.8.csv\n",
      "合并rolling3_skip3_0.8.csv\n",
      "合并rolling3_skip6_0.8.csv\n",
      "合并rolling6_skip13_0.8.csv\n",
      "合并rolling6_skip1_0.8.csv\n",
      "合并rolling6_skip3_0.8.csv\n",
      "合并rolling6_skip6_0.8.csv\n",
      "合并rolling9_skip13_0.8.csv\n",
      "合并rolling9_skip1_0.8.csv\n",
      "合并rolling9_skip6_0.8.csv\n",
      "合并used_all_single_data.csv\n",
      "合并weighted13_skip13_0.8.csv\n",
      "合并weighted13_skip1_0.8.csv\n",
      "合并weighted13_skip3_0.8.csv\n",
      "合并weighted13_skip6_0.8.csv\n",
      "合并weighted3_skip13_0.8.csv\n",
      "合并weighted3_skip1_0.8.csv\n",
      "合并weighted3_skip3_0.8.csv\n",
      "合并weighted3_skip6_0.8.csv\n",
      "合并weighted6_skip13_0.8.csv\n",
      "合并weighted6_skip1_0.8.csv\n",
      "合并weighted6_skip3_0.8.csv\n",
      "合并weighted6_skip6_0.8.csv\n",
      "合并weighted9_skip13_0.8.csv\n",
      "合并weighted9_skip3_0.8.csv\n",
      "合并weighted9_skip6_0.8.csv\n",
      "合并结束，生成新文件：./used_all_single_data.csv\n"
     ]
    }
   ],
   "source": [
    "path  = os.path.abspath('./')\n",
    "file_name_extention='.csv'\n",
    "new_file_name = './used_all_single_data.csv' # 合并后的文件名\n",
    "cols_new_name = ['id','predict_data','mse','rmse','mape','shap','smooth','skip','result_corr']\n",
    "file_allname = []\n",
    "for filename in os.listdir(path):\n",
    "    if os.path.splitext(filename)[1] == file_name_extention and filename != new_file_name:  # 按.csv后缀匹配\n",
    "        t = os.path.splitext(filename)[0]\n",
    "        file_allname.append(t + file_name_extention)  # 拼接.csv后缀，生成完整文件名\n",
    "df = pd.DataFrame(cols_new_name).T\n",
    "\n",
    "try:\n",
    "    print('开始合并：')\n",
    "    df.to_csv(new_file_name, encoding='utf-8', header=False, index=False)\n",
    "    for fn in file_allname:\n",
    "        data = pd.read_csv(path + '/' + fn, header=None)\n",
    "        print('合并' + fn)\n",
    "        data.to_csv(path + '/' + new_file_name, mode='a', encoding='utf-8', header=False, index=False)\n",
    "    print('合并结束，生成新文件：' + new_file_name)\n",
    "except PermissionError as e:\n",
    "    print('出现异常:' + str(type(e)) + '！\\n文件已打开？请先关闭')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vis23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
